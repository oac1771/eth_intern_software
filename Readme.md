# Containerization and Kubernetes Container Orchestration


Prior to the widespread adoption of containerization, applications ran on physical servers with no way to define resource boundaries. This deployment pattern resulted in resource contention between applications running on the same server and difficulty scaling. Containerization, on the other hand, provides a means of isolating applications from the host machine by bundling an application’s code with all of the necessary dependencies into a single software package. Containers have their own file systems, share of CPU, memory, and process space; however, they do not have their own dedicated operating system. Containers only use their host Operating System’s kernel, resulting in a lightweight and efficient form of virtualization. This allows the ability to run hundreds of containerized applications concurrently on a single server.

Containers are built from container images, which are immutable and fully configured application software bundles that cannot be altered by the host machine. Containers are executed by a container runtime which is responsible for running and managing containers on a host system. A runtime provides the low-level functionality needed to create, start, stop, and destroy containers. It also interacts with the host operating and monitoring system resources, ensuring a container does not use more resources than it is allocated. Leveraging container runtimes to manage containers becomes extremely difficult and error prone at scale. Complex scripting is required to manage container deployments, scheduling and deletion across environments all while ensuring proper resource allocation across host servers. Container orchestration platforms, such as Kubernetes, address these challenges by automatically scheduling and scaling containerized applications based on a declarative state.

In Kubernetes, the smallest deployable unit of computing is a group of one or more containers called a Pod. A Pod is an example of a Kubernetes resource, which are objects with which you can interact with using the Kubernetes API. Pods follow a defined life cycle: pending, running, and either succeeded or failed. Kubernetes has two mechanisms to reconcile a failed Pod: attempting to restart it or deleting it entirely. Both of these behaviors can be configured by specifying a restart policy in the pod definition. Deployment, another Kubernetes resource, is used to declaratively describe the desired state for a given application. Deployments can contain information such as the number of desired Pods (replicas), deployment strategies, resource limits, and health checks. Kubernetes uses this state declaration to create any changes needed to bring the current state of deployment in agreement with the desired state.

The architecture behind Kubernetes consists of a control plane and a dynamic set of worker host machines called Nodes. A group of Nodes is called a cluster, and each Node has a dedicated container runtime that is used to execute containers, similar to the container runtimes discussed previously. The control plane’s main responsibilities with respect to container orchestration are serving the Kubernetes API and managing resource controllers. The Kubernetes API acts as an entrypoint to the cluster, allowing users to query and manipulate resources in Kubernetes. For example, a user can leverage the Kubernetes API to query for all Pods. 

Resource controllers are Kubernetes’ main mechanism of performing container orchestration. They continuously track resources and make requests to the Kubernetes API to move the current cluster state closer to the desired state. For example, if a Pod in a Deployment ever enters the failed state in its lifecycle, the Deployment Controller will send a request to the Kubernetes API to create a new Pod to replace it. Kubernetes comes with many built-in resource controllers; however, users can create their own custom resource controllers to track any Resource. This enables Kubernetes users to customize their experience by injecting business logic at any point in the deployment process to be executed automatically.
